---
title: "R Notebook"
editor_options: 
  chunk_output_type: console
---


```{r}
library(MASS)
# library(matrixcalc)
library(Matrix)
library(dplyr)
library(tidyr)

library(fabletools)
library(fable)
library(feasts)

library(devtools)
load_all()
```


```{r}
groups <- c(2,3)
T <-  50
Tsplit <- 40
diag_range <- c(0.5, 0.9)

A <- generate_block_diag(
  groups = groups,
  diag_range = diag_range
)$A

Sigma <- generate_cor(
  groups = groups,
  eidim = 5
)

bottom <- simulate_bottom_var(groups, T, intercept = 100, A=A, Sig=Sigma)

# build_hierarchy(bottom$Y, bottom$groups)$hier_data
```



```{r}
structure <- list(
  groups,
  list(seq(1,length(groups)))
)
S <- construct_S(
  structure = structure,
  sparse = FALSE
)
hts_mat <- bottom$Y %*% t(S)

# info_2level <- build_2level_hierarchy(bottom$Y, bottom$groups)
# S <- info_2level$S
# hts_mat <- info_2level$hier_data
```

*Forecast*

```{r}
hts <- hts_mat %>% 
  as.data.frame() %>% 
  mutate(time = seq(1, nrow(hts_mat))) %>% 
  # select(time, everything()) %>% 
  as_tsibble(index = time) %>% 
  pivot_longer(
    cols = -time,
    names_to = "series",
    values_to = "value"
  )

fit <- hts %>% 
  filter(time <= Tsplit) %>% 
  model(
    arima = ARIMA(value)
  )

fc <- fit |> forecast(h = T-Tsplit)

```


*Get in-sample actual & fitted values*

```{r}
y <- hts_mat[1:Tsplit,]

actual <- hts_mat[(Tsplit + 1):T,]

y_hat <- fit %>% 
  augment() %>% 
  select(series, .fitted) %>%
  pivot_wider(names_from = series, values_from = .fitted, names_sort = FALSE) %>% 
  as_tibble() %>% 
  select(-time) %>% 
  as.matrix()

base_fc <- fc %>% 
  as_tibble() %>% 
  select(series, .mean, time) %>%
  pivot_wider(names_from = series, values_from = .mean) %>%
  select(-time) %>% 
  as.matrix()

y_hat <- y_hat[, colnames(actual)]
base_fc <- base_fc[, colnames(actual)]

all.equal(colnames(y), colnames(y_hat), colnames(base_fc), colnames(actual))
```

```{r}
deltas <- seq(0,1,by=0.05)

W_shr <- shrinkage_est(
  y - y_hat
)

W_n <- novelist_cv(
  y,
  y_hat,
  S,
  window = round(Tsplit/2)
)
```

```{r}
plot(deltas, W_n$errors_by_delta,
  type = "l"
  # ylim = c(results$errors_by_delta %>% min(),results$errors_by_delta %>% mean())
)
points(W_n$delta, W_n$errors_by_delta %>% min(), col = "red")
```

```{r}
recon_mint_shr <- reconcile_mint(base_fc, S, W_shr$cov)
recon_mint_n <- reconcile_mint(base_fc, S, W_n$cov)

# RMSE of my MinT NOVELIST an Shrinkage
sqrt(colMeans((actual - base_fc)^2)) %>% mean()
sqrt(colMeans((actual - recon_mint_shr)^2)) %>% mean()
sqrt(colMeans((actual - recon_mint_n)^2)) %>% mean()
```



# LOOOOOOOOOOOPPPPPPPPPPPPPPP

```{r}
run_loop <- function() {
  
  A <- generate_block_diag(
    groups = groups,
    diag_range = diag_range
  )$A
  Sigma <- generate_cor(
    groups = groups,
    eidim = 5
  )
  bottom <- simulate_bottom_var(groups, T, intercept = 100, A=A, Sig=Sigma)
  
  S <- construct_S(
    structure = structure,
    sparse = FALSE
  )
  hts_mat <- bottom$Y %*% t(S)
  
  # Forecast
  hts <- hts_mat %>% 
    as.data.frame() %>% 
    mutate(time = seq(1, nrow(hts_mat))) %>% 
    # select(time, everything()) %>% 
    as_tsibble(index = time) %>% 
    pivot_longer(
      cols = -time,
      names_to = "series",
      values_to = "value"
    )
  fit <- hts %>% 
    filter(time <= Tsplit) %>% 
    model(
      arima = ARIMA(value)
    )
  fc <- fit |> forecast(h = T-Tsplit)
  
  # Get training and test data
  y <- hts_mat[1:Tsplit,]
  actual <- hts_mat[(Tsplit + 1):T,]
  
  y_hat <- fit %>% 
    augment() %>% 
    select(series, .fitted) %>%
    pivot_wider(names_from = series, values_from = .fitted, names_sort = FALSE) %>% 
    as_tibble() %>% 
    select(-time) %>% 
    as.matrix()
  
  base_fc <- fc %>% 
    as_tibble() %>% 
    select(series, .mean, time) %>%
    pivot_wider(names_from = series, values_from = .mean) %>%
    select(-time) %>% 
    as.matrix()
  
  y_hat <- y_hat[, colnames(actual)]
  base_fc <- base_fc[, colnames(actual)]
  
  if(!all.equal(colnames(y), colnames(y_hat), colnames(base_fc), colnames(actual)))
    stop("Column names do not match")
  
  # Get covariance estimates
  W_shr <- shrinkage_est(
    y - y_hat
  )
  
  W_n <- novelist_cv(
    y,
    y_hat,
    S,
    window = round(Tsplit/2)
  )
  
  recon_mint_shr <- reconcile_mint(base_fc, S, W_shr$cov)
  recon_mint_n <- reconcile_mint(base_fc, S, W_n$cov)
  
  # RMSE of my MinT NOVELIST an Shrinkage
  return(list(
    base = sqrt(colMeans((actual - base_fc)^2)) %>% mean(),
    shrink = sqrt(colMeans((actual - recon_mint_shr)^2)) %>% mean(),
    novelist = sqrt(colMeans((actual - recon_mint_n)^2)) %>% mean()
  ))
}
```

```{r}
groups <- c(2,3)
T <-  100
Tsplit <- 80
diag_range <- c(0.5, 0.9)

structure <- list(
  groups,
  as.list(seq(1,length(groups))),
  list(c(1,2))
)

deltas <- seq(0,1,by=0.05)

run_loop()
```

```{r}
results <- lapply(1:10, function(x) run_loop())

```

```{r}
results <- do.call(rbind, lapply(results, unlist)) %>% as.data.frame()
results$id <- 1:nrow(results)
results <- results %>% melt(id.vars="id")

ggplot(results, aes(x = variable, y = value, fill = variable)) +
  geom_boxplot() +
  labs(x = "Method", y = "Value") +
  theme_minimal()

```



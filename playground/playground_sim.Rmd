---
title: "R Notebook"
editor_options: 
  chunk_output_type: console
---


```{r}
library(MASS)
# library(matrixcalc)
library(Matrix)
library(dplyr)
library(tidyr)

library(fabletools)
library(fable)
library(feasts)

library(devtools)
load_all()
```


```{r}
groups <- c(2,2)
T <-  50
Tsplit <- 40
diag_range <- c(0.5, 0.9)

A <- generate_block_diag(
  groups = groups,
  diag_range = diag_range
)$A

Sigma <- generate_cor(
  groups = groups,
  eidim = 5
)

bottom <- simulate_bottom_var(groups, T, intercept = 100, A=A, Sig=Sigma)

# build_hierarchy(bottom$Y, bottom$groups)$hier_data
```



```{r}
structure <- list(
  groups,
  as.list(seq(1,length(groups))),
  list(c(1,2))
)
S <- construct_S(
  structure = structure,
  sparse = FALSE,
  ascending = FALSE
)
hts_mat <- bottom$Y %*% t(S)

hts <- hts_mat %>% 
  as.data.frame() %>% 
  mutate(time = seq(1, nrow(hts_mat))) %>% 
  # select(time, everything()) %>% 
  as_tsibble(index = time) %>% 
  pivot_longer(
    cols = -time,
    names_to = "series",
    values_to = "value"
  )

hts_slide <- hts %>% 
  tsibble::slide_tsibble(.size = Tsplit) %>% 
  filter(.id <= T-Tsplit)
```




```{r}
fit_slide <- hts_slide %>% 
  model(
    arima = ARIMA(value)
  )

fc_slide <- fit_slide |>
  forecast(h = 8) |>
  group_by(.id, series) |>
  mutate(h = row_number()) |>
  ungroup() |>
  filter(time <= T) |>
  as_fable(response = "value", distribution = value)

fc_slide |>
  accuracy(hts, 
           by = c("h", ".model", "series")) |>
  ggplot(aes(x = h, y = RMSE)) +
    geom_point() +
    facet_wrap(~series)
```

```{r}
# RUN CROSS VALIDATION
# for (i in seq(T-Tsplit)) {
#   
# }

fc_new <- fc_slide
deltas <- seq(0,1,by=0.05)
h <- 8

for (i in seq(T-Tsplit)) {
  message("Iteration: ", i)
  
  start <- i
  end <- i + Tsplit - 1
  test_end <- min(end + h, T)
  
  # Get training and test data
  y <- hts_mat[start:end, rownames(S)]
  actual <- hts_mat[(end + 1):test_end, rownames(S)]
  
  y_hat <- fit_slide %>% 
    augment() %>% 
    filter(.id == i) %>%
    select(series, time, .fitted) %>%
    pivot_wider(names_from = series, values_from = .fitted, names_sort = FALSE) %>% 
    as_tibble() %>% 
    select(-time) %>% 
    as.matrix()
  y_hat <- y_hat[,rownames(S)]
  
  base_fc <- fc_slide %>% 
    as_tibble() %>% 
    filter(.id == i) %>% 
    select(series, .mean, time) %>%
    pivot_wider(names_from = series, values_from = .mean) %>%
    select(-time) %>% 
    as_tibble() %>% 
    as.matrix()
  base_fc <- base_fc[,rownames(S)]
  
  # Get covariance estimates
  W_shr <- shrinkage_est(
    y - y_hat
  )
  W_n <- novelist_cv(
    y,
    y_hat,
    S,
    window = round(Tsplit/2)
  )
  
  # Reconcile
  recon_mint_shr <- reconcile_mint(base_fc, S, W_shr$cov)
  recon_mint_n <- reconcile_mint(base_fc, S, W_n$cov)
  
  # Organise reconciled results into the fc_new object
  shr_fc <- as_tibble(recon_mint_shr) %>% 
    mutate(h = row_number()) %>% 
    pivot_longer(
      cols = -h,
      names_to = "series",
      values_to = ".mean"
    ) %>%
    mutate(
      .id    = i,
      .model = "mint_shrink",
      time   = end + h,
      value  = NA
    ) %>%
    select(.id, series, .model, time, value, .mean, h)
  
  n_fc <- as_tibble(recon_mint_n) %>% 
    mutate(h = row_number()) %>% 
    pivot_longer(
      cols = -h,
      names_to = "series",
      values_to = ".mean"
    ) %>%
    mutate(
      .id    = i,
      .model = "mint_novelist",
      time   = end + h,
      value  = NA
    ) %>%
    select(.id, series, .model, time, value, .mean, h)
  
  fc_new <- bind_rows(fc_new, shr_fc, n_fc)
}

fc_new |>
  accuracy(hts, 
           by = c("h", ".model", "series")) 

fc_new %>% filter(.model != "arima") %>% 
    mutate(value = distributional::dist_normal(.mean, NA)) |>
    accuracy(hts, 
             by = c("h", ".model", "series")) 
```


*Forecast*

```{r}
fit <- hts %>% 
  filter(time <= Tsplit) %>% 
  model(
    arima = ARIMA(value)
  )

fc <- fit |> forecast(h = T-Tsplit)

```


*Get in-sample actual & fitted values*

```{r}
y <- hts_mat[1:Tsplit,]

actual <- hts_mat[(Tsplit + 1):T,]

y_hat <- fit %>% 
  augment() %>% 
  select(series, .fitted) %>%
  pivot_wider(names_from = series, values_from = .fitted, names_sort = FALSE) %>% 
  as_tibble() %>% 
  select(-time) %>% 
  as.matrix()

base_fc <- fc %>% 
  as_tibble() %>% 
  select(series, .mean, time) %>%
  pivot_wider(names_from = series, values_from = .mean) %>%
  select(-time) %>% 
  as.matrix()

y_hat <- y_hat[, colnames(actual)]
base_fc <- base_fc[, colnames(actual)]

all.equal(colnames(y), colnames(y_hat), colnames(base_fc), colnames(actual))
```

```{r}
deltas <- seq(0,1,by=0.05)

W_shr <- shrinkage_est(
  y - y_hat
)

W_n <- novelist_cv(
  y,
  y_hat,
  S,
  window = round(Tsplit/2)
)
```

```{r}
plot(deltas, W_n$errors_by_delta,
  type = "l"
  # ylim = c(results$errors_by_delta %>% min(),results$errors_by_delta %>% mean())
)
points(W_n$delta, W_n$errors_by_delta %>% min(), col = "red")
```

```{r}
recon_mint_shr <- reconcile_mint(base_fc, S, W_shr$cov)
recon_mint_n <- reconcile_mint(base_fc, S, W_n$cov)

# RMSE of my MinT NOVELIST an Shrinkage
sqrt(colMeans((actual - base_fc)^2)) %>% mean()
sqrt(colMeans((actual - recon_mint_shr)^2)) %>% mean()
sqrt(colMeans((actual - recon_mint_n)^2)) %>% mean()
```



# LOOOOOOOOOOOPPPPPPPPPPPPPPP

```{r}
run_loop <- function() {
  
  A <- generate_block_diag(
    groups = groups,
    diag_range = diag_range
  )$A
  Sigma <- generate_cor(
    groups = groups,
    eidim = 5
  )
  bottom <- simulate_bottom_var(groups, T, intercept = 100, A=A, Sig=Sigma)
  
  S <- construct_S(
    structure = structure,
    sparse = FALSE
  )
  hts_mat <- bottom$Y %*% t(S)
  
  # Forecast
  hts <- hts_mat %>% 
    as.data.frame() %>% 
    mutate(time = seq(1, nrow(hts_mat))) %>% 
    # select(time, everything()) %>% 
    as_tsibble(index = time) %>% 
    pivot_longer(
      cols = -time,
      names_to = "series",
      values_to = "value"
    )
  fit <- hts %>% 
    filter(time <= Tsplit) %>% 
    model(
      arima = ARIMA(value)
    )
  fc <- fit |> forecast(h = T-Tsplit)
  
  # Get training and test data
  y <- hts_mat[1:Tsplit,]
  actual <- hts_mat[(Tsplit + 1):T,]
  
  y_hat <- fit %>% 
    augment() %>% 
    select(series, .fitted) %>%
    pivot_wider(names_from = series, values_from = .fitted, names_sort = FALSE) %>% 
    as_tibble() %>% 
    select(-time) %>% 
    as.matrix()
  
  base_fc <- fc %>% 
    as_tibble() %>% 
    select(series, .mean, time) %>%
    pivot_wider(names_from = series, values_from = .mean) %>%
    select(-time) %>% 
    as.matrix()
  
  y_hat <- y_hat[, colnames(actual)]
  base_fc <- base_fc[, colnames(actual)]
  
  if(!all.equal(colnames(y), colnames(y_hat), colnames(base_fc), colnames(actual)))
    stop("Column names do not match")
  
  # Get covariance estimates
  W_shr <- shrinkage_est(
    y - y_hat
  )
  
  W_n <- novelist_cv(
    y,
    y_hat,
    S,
    window = round(Tsplit/2)
  )
  
  recon_mint_shr <- reconcile_mint(base_fc, S, W_shr$cov)
  recon_mint_n <- reconcile_mint(base_fc, S, W_n$cov)
  
  # RMSE of my MinT NOVELIST an Shrinkage
  return(list(
    base = sqrt(colMeans((actual - base_fc)^2)) %>% mean(),
    shrink = sqrt(colMeans((actual - recon_mint_shr)^2)) %>% mean(),
    novelist = sqrt(colMeans((actual - recon_mint_n)^2)) %>% mean()
  ))
}
```

```{r}
groups <- c(2,3)
T <-  100
Tsplit <- 80
diag_range <- c(0.5, 0.9)

structure <- list(
  groups,
  as.list(seq(1,length(groups))),
  list(c(1,2))
)

deltas <- seq(0,1,by=0.05)

run_loop()
```

```{r}
results <- lapply(1:10, function(x) run_loop())

```

```{r}
results <- do.call(rbind, lapply(results, unlist)) %>% as.data.frame()
results$id <- 1:nrow(results)
results <- results %>% melt(id.vars="id")

ggplot(results, aes(x = variable, y = value, fill = variable)) +
  geom_boxplot() +
  labs(x = "Method", y = "Value") +
  theme_minimal()

```


